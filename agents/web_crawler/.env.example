# Crawler Settings
CRAWLER_MAX_PAGES=100
CRAWLER_MAX_DEPTH=3
CRAWLER_TIMEOUT=30
CRAWLER_MAX_TOTAL_TIME=120

CRAWLER_MAX_CONCURRENT_PAGES=5 
CRAWLER_MEMORY_THRESHOLD=80.0
CRAWLER_USER_AGENT="Crawl4AI Agent/1.0"

CRAWLER_RESPECT_ROBOTS=true
CRAWLER_DEBUG=false

# Database
POSTGRES_HOST=<POSTGRES_HOST>
POSTGRES_PORT=5432
POSTGRES_USER=<USER>
POSTGRES_PASSWORD=<PASSWORD
POSTGRES_DB=web_crawler

# Redis
REDIS_HOST=<REDIS_HOST>
REDIS_PORT=6379
REDIS_DB=0

# Proxy Settings (if needed)
CRAWLER_PROXY_URL=
CRAWLER_PROXY_USERNAME=
CRAWLER_PROXY_PASSWORD=

# Browser Settings
CRAWLER_HEADLESS=true
CRAWLER_VIEWPORT_WIDTH=1920
CRAWLER_VIEWPORT_HEIGHT=1080

# Domain and Pattern Settings
CRAWLER_ALLOWED_DOMAINS=ai.pydantic.dev,example.com
CRAWLER_SITE_URL=https://ai.pydantic.dev,https://example.com
CRAWLER_EXCLUDE_PATTERNS=*.pdf,*.jpg,*.png,*.gif,*.zip

# Cleanup Settings
CRAWLER_CLEANUP_INTERVAL_HOURS=24
CRAWLER_DATA_RETENTION_DAYS=30

# Ollama settings   
OLLAMA_BASE_URL=http://home.server:30080/ollama
OLLAMA_MODEL=qwen2.5vl:7b